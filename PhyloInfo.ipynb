{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Library imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter, defaultdict\n",
    "import itertools\n",
    "import statistics\n",
    "from newick import loads\n",
    "import pprint\n",
    "import math\n",
    "import random \n",
    "import io\n",
    "from io import StringIO\n",
    "import sys\n",
    "import re\n",
    "import copy\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "from ete3 import Tree\n",
    "\n",
    "# BioPython\n",
    "from Bio import SeqIO, Phylo, AlignIO\n",
    "from Bio.Phylo.TreeConstruction import DistanceCalculator, DistanceTreeConstructor\n",
    "from Bio.Phylo import draw\n",
    "from Bio.Align import MultipleSeqAlignment\n",
    "from Bio.Phylo.BaseTree import Clade\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(font='Hiragino Maru Gothic Pro', context='notebook', style='white')\n",
    "plt.figure(figsize=(20,12))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use sample data\n",
    "input_data = \"sample_seq/acc_hcov_pro_align_fix.fasta\"\n",
    "\n",
    "tree_check_file = [\n",
    "    \"sample_tree/hcov_pro_jcgap_root.txt\",\n",
    "    \"sample_tree/hcov_pro_jccomp_root.txt\",\n",
    "    \"sample_tree/hcov_pro_jcpair_root.txt\",\n",
    "    \"sample_tree/hcov_pro_DAYHOFF_raxml_root.txt\",\n",
    "    \"sample_tree/hcov_pro_JTTG_raxml_root.txt\",\n",
    "    \"sample_tree/hcov_pro_poisson_bayes_root.txt\",\n",
    "    \"sample_tree/hcov_pro_jttg_bayes_root.txt\",\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Newick tree format\n",
    "def change_tree_format(newick_list):\n",
    "    tree_list_new = []\n",
    "    for newick in newick_list:\n",
    "        with open(newick, 'r') as file:\n",
    "            tree_tmp = file.read()\n",
    "            \n",
    "        # Cut species names at spaces\n",
    "        otus = re.findall(r\"'(.*?)'\", tree_tmp)\n",
    "        otus_rep = [s.split(\" \")[0].replace(\"(\",\"-\").replace(\")\",\"-\").replace(';','-').replace(',','-').replace(\"@\",\"-\") for s in otus]\n",
    "        rep_dict = dict(zip(otus, otus_rep))\n",
    "        for k,v in rep_dict.items():\n",
    "            tree_tmp = tree_tmp.replace(k,v)\n",
    "        tree_tmp = tree_tmp.replace(\"'\",\"\")\n",
    "        tree_list_new.append(tree_tmp)\n",
    "        \n",
    "    return tree_list_new\n",
    "tree_check_list = change_tree_format(tree_check_file)\n",
    "\n",
    "# Convert to BioPython format\n",
    "align_seq = AlignIO.read(input_data, \"fasta\")\n",
    "\n",
    "# Display number of sequences and sequence length\n",
    "print(f\"Number of sequences: {len(align_seq)}\")\n",
    "print(f\"Length: {len(align_seq[0].seq)}\")\n",
    "\n",
    "# Store sequence data for information content calculation\n",
    "sequences_raw = {}\n",
    "char_list = [] # Store occurring characters\n",
    "\n",
    "for record in align_seq:\n",
    "    # Replace characters that affect subsequent processing\n",
    "    otu = str(record.id.replace(';','-').\n",
    "              replace(',','-').\n",
    "              replace(\"@\",\"-\").\n",
    "              replace(\"(\",\"-\").\n",
    "              replace(\")\",\"-\").replace(' ','-'))    \n",
    "    seq = str(record.seq)\n",
    "    \n",
    "    # Check types of characters present\n",
    "    char_list += list(set(seq))\n",
    "    \n",
    "    # Store in dict\n",
    "    sequences_raw[otu] = [seq[i:i + 1] for i in range(len(seq))]\n",
    "    \n",
    "# List of characters used\n",
    "char_list = list(set(char_list))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decide internal nodes & Calculate amount of information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to read Newick format tree and sequence, and get combinations of (parent, child, child) from leaves\n",
    "def get_node_val(sequences, tree, df_nodedist):\n",
    "    # Regular expression to extract innermost parentheses (A,B)\n",
    "    cladeReg = '\\(([^\\(\\)]+)\\)'\n",
    "    sequences_val = sequences.copy()\n",
    "    mutual_info = []\n",
    "    \n",
    "    while re.search(cladeReg, tree):\n",
    "        \n",
    "        # Extract the most terminal pair\n",
    "        match = re.search(cladeReg, tree)\n",
    "        clade = match.group()\n",
    "        \n",
    "        leaf_A = clade.split(',')[0].replace('(','')\n",
    "        leaf_B = clade.split(',')[1].replace(')','')\n",
    "        \n",
    "        if ':' in leaf_A:\n",
    "            leaf_A = leaf_A.split(':')[0]\n",
    "        if ':' in leaf_B:\n",
    "            leaf_B = leaf_B.split(':')[0]\n",
    "        \n",
    "        if 'Inner' in leaf_A:\n",
    "            leaf_A = leaf_A.split('Inner')[0]\n",
    "        if 'Inner' in leaf_B:\n",
    "            leaf_B = leaf_B.split('Inner')[0]\n",
    "            \n",
    "        \n",
    "        # Create internal node name\n",
    "        node_name = leaf_A + '@' + leaf_B\n",
    "        \n",
    "        # Get list of differences between current internal node and leaf nodes\n",
    "        node_dist = df_nodedist.loc[node_name].to_dict()\n",
    "        \n",
    "        # Determine & save parent sequence\n",
    "        sequences_val[node_name] = deside_parent_seq_lgs(sequences, node_dist)\n",
    "        \n",
    "        \n",
    "        # Calculate mutual information between current internal node and its two children\n",
    "        mutual_info_part = sum_mutual_info_normalized(sequences_val[leaf_A],\n",
    "                                           sequences_val[leaf_B],\n",
    "                                           sequences_val[node_name])\n",
    "        \n",
    "        # Save pair name & update tree\n",
    "        tree = tree.replace(match.group(), node_name)\n",
    "        \n",
    "        \n",
    "        mutual_info.append(mutual_info_part)\n",
    "        \n",
    "    return mutual_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to predict internal node sequences\n",
    "def deside_parent_seq_lgs(sequences, node_dist):\n",
    "        \n",
    "    global char_list # List of characters appearing in the current dataset\n",
    "    \n",
    "    lgs = len(sequences[next(iter(sequences))]) # Sequence length\n",
    "    \n",
    "    # Optimize for each site\n",
    "    parent_seq = []\n",
    "    for i in range(lgs):\n",
    "        \n",
    "        site_dist_min = 1000000\n",
    "        site_dist_min_char = \"\"\n",
    "        \n",
    "        for c in char_list: # Character for parent site\n",
    "            # Sum weighted distances between current internal node and all leaf nodes\n",
    "            d = 0\n",
    "            \n",
    "            for seq in sequences.keys():\n",
    "                if sequences[seq][i] != c: # Count if mismatch\n",
    "                    d += node_dist[seq]\n",
    "                 \n",
    "            if d < site_dist_min:\n",
    "                site_dist_min = d\n",
    "                site_dist_min_char = c\n",
    "    \n",
    "        parent_seq.append(site_dist_min_char)\n",
    "        \n",
    "    return parent_seq\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to assign names connected by @ to internal nodes\n",
    "def assign_at_names(node):\n",
    "    if node.is_leaf():\n",
    "        return node.name\n",
    "    else:\n",
    "        child_names = []\n",
    "        for child in node.children:\n",
    "            child_name = assign_at_names(child)\n",
    "            child_names.append(child_name)\n",
    "        # Create name by connecting subtrees with @\n",
    "        node.name = \"@\".join(child_names)\n",
    "        return node.name\n",
    "    \n",
    "# Function to calculate the maximum distance between two leaf nodes in the phylogenetic tree (L_max)\n",
    "def get_max_leaf_distance(tree):\n",
    "    leaves = tree.get_leaves()\n",
    "    max_distance = 0\n",
    "   \n",
    "    for leaf1 in leaves:\n",
    "        for leaf2 in leaves:\n",
    "            if leaf1 != leaf2:\n",
    "                distance = tree.get_distance(leaf1, leaf2)\n",
    "                if distance > max_distance:\n",
    "                    max_distance = distance\n",
    "   \n",
    "    return max_distance\n",
    "    \n",
    "# Function to calculate distances between internal nodes and leaves, storing in a dataframe\n",
    "def get_dist(newick_str):\n",
    "    tree = Tree(newick_str, format=1)\n",
    "    assign_at_names(tree)\n",
    "    leaves = tree.get_leaves()\n",
    "    leaf_names = [leaf.name for leaf in leaves]\n",
    "    internal_nodes = [node for node in tree.traverse() if not node.is_leaf()]\n",
    "    \n",
    "    data = {}\n",
    "    for internal_node in internal_nodes:\n",
    "        distances = []\n",
    "        for leaf in leaves:\n",
    "            # Find MRCA (Most Recent Common Ancestor)\n",
    "            mrca = tree.get_common_ancestor(internal_node, leaf)\n",
    "            # Add the distance from MRCA to internal node and from MRCA to leaf\n",
    "            distance = internal_node.get_distance(mrca) + leaf.get_distance(mrca)\n",
    "            distances.append(distance)\n",
    "        data[internal_node.name] = distances\n",
    "    \n",
    "    # Create dataframe\n",
    "    df = pd.DataFrame(data, index=leaf_names).transpose()\n",
    "    \n",
    "    # Convert to weights\n",
    "    L_max = get_max_leaf_distance(tree)\n",
    "    df = L_max - df \n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate the amount of information in (parent, child, child)\n",
    "def sum_mutual_info_normalized(c1, c2, p):\n",
    "    # Common length\n",
    "    n = len(p)\n",
    "    \n",
    "    # Frequency counts\n",
    "    nuc_count_xz = Counter([(a, c) for a, c in zip(c1, p)])\n",
    "    nuc_count_yz = Counter([(b, c) for b, c in zip(c2, p)])    \n",
    "    nuc_count_x = Counter(c1)\n",
    "    nuc_count_y = Counter(c2)\n",
    "    nuc_count_z = Counter(p)\n",
    "    \n",
    "    # Entropy of Z: S(Z)\n",
    "    S_z = 0.0\n",
    "    for z, count_z in nuc_count_z.items():\n",
    "        P_z = count_z / n\n",
    "        if P_z > 0:\n",
    "            S_z -= P_z * math.log2(P_z)\n",
    "            \n",
    "    # Mutual information between X and Z: MI(X; Z)\n",
    "    I_xz = 0.0\n",
    "    for (x, z), count_xz in nuc_count_xz.items():\n",
    "        P_xz = count_xz / n\n",
    "        P_x = nuc_count_x[x] / n\n",
    "        P_z = nuc_count_z[z] / n\n",
    "        if P_xz > 0 and P_x > 0 and P_z > 0:\n",
    "            I_xz += P_xz * math.log2(P_xz / (P_x * P_z))\n",
    "        \n",
    "    # Mutual information between Y and Z: MI(Y; Z)\n",
    "    I_yz = 0.0\n",
    "    for (y, z), count_yz in nuc_count_yz.items():\n",
    "        P_yz = count_yz / n\n",
    "        P_y = nuc_count_y[y] / n\n",
    "        P_z = nuc_count_z[z] / n\n",
    "        if P_yz > 0 and P_y > 0 and P_z > 0:\n",
    "            I_yz += P_yz * math.log2(P_yz / (P_y * P_z))\n",
    "            \n",
    "    # Normalized values: MI(X; Z) / S(Z) and MI(Y; Z) / S(Z)\n",
    "    normalized_I_xz = I_xz / S_z if S_z > 0 else 0\n",
    "    normalized_I_yz = I_yz / S_z if S_z > 0 else 0\n",
    "    \n",
    "    return normalized_I_xz + normalized_I_yz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i, tree in enumerate(tree_check_list):\n",
    "    # Display filenames\n",
    "    print(tree_check_file[i])\n",
    "    \n",
    "    df_nodedist = get_dist(tree)\n",
    "    res = get_node_val(sequences_raw, tree, df_nodedist)\n",
    "    \n",
    "    # Average mutual information (divide by 2 to get value per parent-child pair)\n",
    "    res_mean = np.mean(res)/2\n",
    "    \n",
    "    # Display results\n",
    "    print(round(res_mean, 4))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
